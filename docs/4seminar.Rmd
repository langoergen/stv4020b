---
title: "Seminar 4"
author: "Martin SÃ¸yland"
output:
  html_document:
  urlcolor: cyan
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = FALSE)
knitr::opts_knit$set(root.dir = "../")
options(width = 100)

rm(list = ls())
```

# A note on logits to probabilities

Last week, I introduced some confusion by converting logits to probabilities in a non-standard way. The one you are used to and the one from last week are essentially the same:
```{r a_note}

x.beta0 <- 1:5
first <- 1 / (1 + exp(-x.beta0))
second <- exp(x.beta0) / (1 + exp(x.beta0))
cbind(first, second)
```

# Hendrix and Salehyan (2004)

<blockquote>
  The results indicatethat rainfall variability has a significant effect on both large-scale and smaller-scale instances of political conflict.
</blockquote>

## Reading the data, yet again from STATA

We read the dataset, and get a quick overview with `str()`

```{r reading_data}
library(haven)

rain_raw <- read_dta("./data/H_S_JPR_491_Replication_Revised.dta")

rain_raw[1:10, 1:6]

```


Next, we look into the dependent and main independent variables.
```{r dep_var}

summary(rain_raw$events_no_onset)

library(ggplot2)

ggplot(rain_raw, aes(x = events_no_onset)) +
  geom_histogram(binwidth = 1) +
  theme_classic() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid.major.y = element_line(color = "gray70"))

ggplot(rain_raw, aes(x = GPCP_precip_mm_deviation_sd, GPCP_precip_mm_deviation_sd_sq)) + 
  geom_line() +
  theme_classic()
```

We then replicate figure 1 from the paper. Do note that the data have the plot points for 2009, as is included in the paper.

```{r fig1}
library(dplyr)

rain_raw %>% 
  group_by(year) %>% 
  summarize(events_no_onset = sum(events_no_onset, na.rm = TRUE)) %>% 
  filter(year >= 1990) %>% 
  ggplot(aes(x = year, y = events_no_onset)) + 
  geom_point(size = 5, shape = 18) +
  geom_line(size = 1) +
  scale_y_continuous(breaks = seq(0, 500, 50), limits = c(0, 500)) +
  scale_x_continuous(breaks = seq(1990, 2015, 1)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(color = "gray70"),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.ticks = element_blank())
```

## The model (in poisson)

The poisson distribution looks something like this:
```{r pois_distrib}

ggplot(NULL, aes(x = rpois(1000, 1.5))) + 
  stat_density(adjust = 3, geom = "line") + 
  theme_classic()

```

More on this in the lecture!


```{r poisson}

rain <- rain_raw %>%
  filter(ccode != 520) # Somalia is removed in the paper (see footnote 13)

# Poisson -- why it does not work in this application
poisson <- glm(events_no_onset ~                    # count of social conflict events
                 events_no_onset_l +                # lagged social conflict events
                 GPCP_precip_mm_deviation_sd  +     # rainfall deviation
                 GPCP_precip_mm_deviation_sd_sq +   # squared rainfall deviation
                 GPCP_precip_mm_deviation_sd_l +    # lagged rainfall deviation
                 GPCP_precip_mm_deviation_sd_l_sq + # lagged squared rainfall deviation
                 polity2 +                          # polity2
                 polity2_sq +                       # squared polity 2
                 log_pop_pwt +                      # log(population size)
                 log_pop_pwt_fd  +                  # population growth
                 log_rgdpch_pwt +                   # log(gdp per capita)
                 grgdpch_pwt +                      # real gdp growth
                 incidence +                        # civil conflict
                 ttrend +                           # time trend
                 factor(year),                      # year dummies
               family = "poisson",                  #this is how we specify that want a poisson model.
               data = rain)
summary(poisson)

# Do notice the dummy of 2007! It's just NA ...
# This means that the variable is linearly related to
# the other variables in the regression
# STATA seems to not report this to the user!

```

# Clustered standard errors

The article also makes use of clustered standard errors on country. This should be pretty easy to do by now!

```{r clustered_st}

## clustering the variance covariance matrix on country:
library(multiwayvcov)
poisson.cluster.vcov <- cluster.vcov(poisson, cluster = rain$ccode)

## Model summary with clustered standard errors:
library(lmtest)
coeftest(poisson, vcov = poisson.cluster.vcov)

# Look! It is the same
cbind(sqrt(diag(poisson.cluster.vcov)), coeftest(poisson, vcov = poisson.cluster.vcov)[, "Std. Error"])
```

# Negative binomial

However, the article make use of the negative binomial regression for good reasons. There is a fair amount of overdispersion.

```{r overdispersion}
mean(rain$events_no_onset, na.rm = TRUE)

var(rain$events_no_onset, na.rm = TRUE) 

```
Also, more on this in the lecture!

The negative binomial contrasts to the poisson like this:
```{r negbin_distrib}
set.seed(615564)
ggplot(NULL) + 
  stat_density(aes(x = MASS::rnegbin(1000, mu = 1, 1.5)), adjust = 2, geom = "line", color = "blue") + 
  stat_density(aes(x = rpois(1000, 1)), adjust = 3, geom = "line", color = "darkred") +
  scale_x_continuous(breaks = seq(0, 10, 1)) +
  theme_classic()

```


From the paper:
<blockquote>
Negative binomial models are similar to other event count models, such as Poisson regression, but are more appropriate for over-dispersed data.
</blockquote>

Negative binomial models can be estimated using `glm.nb()` from the MASS package.

We will do a replication of Model 2, page 44 in original article:
```{r negbin_reg}

library(MASS)

negBinomial <- glm.nb(events_no_onset ~                      # count of social conflict events
                        events_no_onset_l +                  # lagged social conflict events
                        GPCP_precip_mm_deviation_sd +        # rainfall deviation
                        GPCP_precip_mm_deviation_sd_sq +     # squared rainfall deviation
                        GPCP_precip_mm_deviation_sd_l +      # lagged rainfall deviation
                        GPCP_precip_mm_deviation_sd_l_sq +   # lagged squared rainfall deviation
                        polity2 +                            # polity2
                        polity2_sq +                         # squared polity 2
                        log_pop_pwt +                        # log(population size)
                        log_pop_pwt_fd  +                    # population growth
                        log_rgdpch_pwt +                     # log(gdp per capita)
                        grgdpch_pwt +                        # real gdp growth
                        incidence +                          # civil conflict
                        ttrend +                             # time trend
                        factor(year),                        # year dummies
                      data = rain)

summary(negBinomial)

## clustering the variance covariance matrix on country:
negBinomial.cluster.vcov <- cluster.vcov(negBinomial, cluster = rain$ccode)

## summary with clustered standard errors:
coeftest(negBinomial, negBinomial.cluster.vcov)
```

# Incidence Rate Ratio (IRR)

The coefficients from negative binomial regressions can be hard to intepret. Exponentiated coeffients can be interpreted as incidence rate ratios which are the relative difference in the rate of event occurences.

We can make a function for calculating this in stargazer
```{r irr}

irr.ci <- function(model, z = 1.96, v.cov = vcov(model)){
  list(
    irr = list(exp(model$coef)),
    ci = list(cbind(exp((model$coef - z * sqrt(diag(v.cov)))),
                    exp((model$coef + z * sqrt(diag(v.cov))))))
  )
}
```


```{r irr_table, results='asis'}
library(stargazer)
### Making a nice table to compare the two models:
stargazer(poisson, negBinomial,
          coef=c(irr.ci(poisson)$irr, irr.ci(negBinomial)$irr),
          ci= TRUE,
          ci.custom = c(irr.ci(poisson, v.cov=poisson.cluster.vcov)$ci,
                        irr.ci(negBinomial,v.cov=negBinomial.cluster.vcov)$ci),
          omit=c("ttrend","year"),
          omit.labels=c("Time trend", "Year dummies"),
          p.auto = FALSE,
          type="html")
```

Which model is better?

The poission model is nested in the negative binomial model. We may thus use a likelihood ratio test or compare AIC/BIC between them:

```{r test}
lrtest(poisson, negBinomial)  ## We are testing the null hypothesis that they fit as well. This null hypothesis is rejected
AIC(poisson, negBinomial)
BIC(poisson, negBinomial)
```

# Simultation: Woohoo!

```{r simulation}

### simulating effects:
simb <- mvrnorm(n = 1000,
               mu = na.omit(negBinomial$coefficients), # the list of coefs has an additional dummy for the flawed category 2007
               Sigma = negBinomial.cluster.vcov)       # whereas the vcov does not


## Setting a range for the variable of interest
range.GPCP_precip_mm_deviation_sd <- seq(from = min(rain$GPCP_precip_mm_deviation_sd),
                                         to = max(rain$GPCP_precip_mm_deviation_sd),
                                         length.out = 50)


## Creating a scenario with 0 lagged conflict, other variables at mean and 1999 as the year
set.x <- cbind(1, # intercept,
               0, # no lagged conflict in t-1
               range.GPCP_precip_mm_deviation_sd, # our range of rainfall deviations,
               range.GPCP_precip_mm_deviation_sd^2,
               mean(rain$GPCP_precip_mm_deviation_sd_l,na.rm = TRUE),
               mean(rain$GPCP_precip_mm_deviation_sd_l_sq,na.rm = TRUE),
               mean(rain$polity2,na.rm = TRUE),
               mean(rain$polity2_sq, na.rm = TRUE),
               mean(rain$log_pop_pwt, na.rm = TRUE),
               mean(rain$log_pop_pwt_fd, na.rm = TRUE),
               mean(rain$log_rgdpch_pwt, na.rm = TRUE), mean(rain$grgdpch_pwt,na.rm = TRUE),0,
               median(rain$ttrend), 
               0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0) # year dummies

## calculating the expected count
x.beta <- set.x %*% t(simb)

exp.y <- exp(x.beta) # exp gives counts with this model!


## Creating a set og points to use in the plot
quantile.values <- apply(X = exp.y, MARGIN = 1, FUN = quantile, probs = c(.025, .5, .975))

plot.points <- data.frame(cbind(range.GPCP_precip_mm_deviation_sd, t(quantile.values)))

names(plot.points) <- c("range_rain_dev", "lwr", "m", "upr")

## Making figure 2 (only with counts, not %):
ggplot(plot.points, aes(x = range_rain_dev, y = m)) +
  geom_line() +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .2) +
  labs(x = "Rainfall deviation", y = "Predicted counts") +
  scale_y_continuous(breaks = seq(0, 15, 2), limits = c(0, 14.5)) +
  scale_x_continuous(breaks = seq(-4, 4, 1)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(color = "gray70"),
        axis.line = element_blank(),
        axis.ticks = element_blank())
```

# Bootstrapping: More fun!

[From Wiki](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)):
"Bootstrapping is the practice of estimating properties of an estimator (such as its variance) by measuring those properties when sampling from an approximating distribution."

Lets bootstrap the theta from the negative binomial regression as an illustration (see: https://stats.stackexchange.com/a/103579)

```{r theta_boot}

negBinomial$theta


theta_boot <- function(n_rows){

  # Extracting the rows to run the regression on
  rows <- sample(1:nrow(rain), n_rows)

  # Running the regression on random
  tmp <- negBinomial <- glm.nb(events_no_onset ~
                          events_no_onset_l +
                          GPCP_precip_mm_deviation_sd  +
                          GPCP_precip_mm_deviation_sd_sq +
                          GPCP_precip_mm_deviation_sd_l +
                          GPCP_precip_mm_deviation_sd_l_sq +
                          polity2 +
                          polity2_sq +
                          log_pop_pwt +
                          log_pop_pwt_fd  +
                          log_rgdpch_pwt +
                          grgdpch_pwt +
                          incidence +
                          ttrend +
                          factor(year),
                        data = rain[rows, ])

  return(tmp$theta)
}

# setting seed to get same results on each run
set.seed(58793)

# testing the function
theta_boot(nrow(rain) / 2)

# running it 50 times (should be more, but it is time consuming)
hm <- sapply(1:50, function(x) theta_boot(nrow(rain) / 2))

# extracting 95% interval
quantile(hm, c(.025, .5, .975))
```

This can be done on a lot of statistical measures (R-squared for example). But we can also do it in order to get standard errors!

Bootstrapping approach to standard errors:
1. draw random samples with replacement repeatedly from the sample dataset;
2. estimate the desired statistic corresponding to these bootstrap samples, which
   forms the sampling distribution of the coefficients; and
3. calculate the sample standard deviation of the sampling distribution

```{r std_boot}


### using the boot function:

## we need a function that the boot can use:
bs.negbin <- function(formula, data, rows) {
  subset_data <- data[rows, ]                   # tells boot to select samples from the data

  fit <- glm.nb(formula, data = subset_data)    # estimating the model

  return(coefficients(fit))           # returning the coefficients from the model
}

# bootstrapping with 100 replications
library(boot)
set.seed(58793)
boots <- boot(data = rain,           # the data argument
              statistic = bs.negbin, # the statistic we want the bootstrap for. Here this is the function defined above
              R = 100,               # the number of bootstrap replicates. You may want to increase it, but that will mean that the code needs more time to run!
              formula =              # the formula which is used with our bs.negbin function:
                events_no_onset ~ events_no_onset_l + GPCP_precip_mm_deviation_sd +
                GPCP_precip_mm_deviation_sd_sq + GPCP_precip_mm_deviation_sd_l +
                GPCP_precip_mm_deviation_sd_l_sq + polity2 + polity2_sq +
                log_pop_pwt + log_pop_pwt_fd + log_rgdpch_pwt + grgdpch_pwt +
                incidence + ttrend + factor(year))

## retrieving the standard error
## this standard error is just the standard deviation of the bootstap replicates of the coefs:
apply(boots$t, 2, sd)

data.frame(vanilla = sqrt(diag(vcov(negBinomial))), 
           clustered = sqrt(diag(negBinomial.cluster.vcov)), 
           boots = na.omit(apply(boots$t, 2, sd)))

```

# Zero-inflated models and hurdle models

What if the zeroes are produced by a different process than the counts?

Two options:
1. In a hurdle model, a truncated count component is employed for positive counts, and a hurdle component models zero vs. larger counts
2. The zero-inflated model is another option. The approach is similar, but in contrast to in the hurdle model, the outcome of the count process can also be zero. Moreover, the modelling of the excess zeroes is always binomial.

Hurdle models be specified using the `hurdle()` function from the pscl package. Zero inflated models can be obtained through the function `zeroinfl()` in the same package.

(Please note that these models are probably not optimally speficied, they do, however, illustrate how the models may be estimated in R) 

```{r zero_hurdle}

library(pscl)

hurdle <- hurdle(events_no_onset ~  # dependent variable
                   # truncated count component:
                   events_no_onset_l + GPCP_precip_mm_deviation_sd  + GPCP_precip_mm_deviation_sd_sq +
                   GPCP_precip_mm_deviation_sd_l + GPCP_precip_mm_deviation_sd_l_sq + polity2 +
                   polity2_sq + log_pop_pwt + log_pop_pwt_fd + log_rgdpch_pwt + grgdpch_pwt + incidence +
                   ttrend  |
                   ## hurdle component:
                   events_no_onset_l + GPCP_precip_mm_deviation_sd  + GPCP_precip_mm_deviation_sd_sq +
                   GPCP_precip_mm_deviation_sd_l + GPCP_precip_mm_deviation_sd_l_sq + polity2 +
                   polity2_sq + log_pop_pwt + log_pop_pwt_fd + log_rgdpch_pwt + grgdpch_pwt + incidence +
                   ttrend,
                 data = rain,
                 dist = "negbin", zero.dist = "binomial", link = "logit")
summary(hurdle)
# alternative to stargazer
library(texreg)
screenreg(hurdle)

```

```{r hurdle_table,results='asis'}

htmlreg(hurdle)
```

```{r zinfl}
zeroinflated <- zeroinfl(events_no_onset ~  # dependent variable
                          # truncated count component:
                          events_no_onset_l + GPCP_precip_mm_deviation_sd  + GPCP_precip_mm_deviation_sd_sq +
                          GPCP_precip_mm_deviation_sd_l + GPCP_precip_mm_deviation_sd_l_sq + polity2 +
                          polity2_sq + log_pop_pwt + log_pop_pwt_fd + log_rgdpch_pwt + grgdpch_pwt + incidence +
                          ttrend  |
                          ## model of excess zeroes:
                          events_no_onset_l + GPCP_precip_mm_deviation_sd  + GPCP_precip_mm_deviation_sd_sq +
                          GPCP_precip_mm_deviation_sd_l + GPCP_precip_mm_deviation_sd_l_sq + polity2 +
                          polity2_sq + log_pop_pwt + log_pop_pwt_fd + log_rgdpch_pwt + grgdpch_pwt,
                        data = rain,
                        dist = "negbin",  link = "logit")

summary(zeroinflated)

screenreg(zeroinflated)


```

```{r zinf_table,results='asis'}
htmlreg(zeroinflated)
```

```{r cowsay,results='asis'}
cowsay::say("Good luck with assignment 4!!!", "cow")
```

```{r ikketenkpÃ¥denne, eval=FALSE, echo=FALSE}
knitr::purl("./docs/4seminar.Rmd", output = "./scripts/4seminar.R", documentation = 1)
```